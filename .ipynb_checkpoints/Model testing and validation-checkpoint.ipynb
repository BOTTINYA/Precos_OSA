{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import preprocessing\n",
    "import data\n",
    "import metrics\n",
    "import parameters\n",
    "import functions\n",
    "\n",
    "from time import time\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction for training model\n",
    "df = data.data_extraction.BDD_Promo('csv')\n",
    "#Data Cleaning\n",
    "df = preprocessing.training_set_preprocessing.training_set_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de la grille de paramètres pour un grid search\n",
    "xgb_grid = {'max_depth':[5,7,9], \n",
    "            'learning_rate':[0.1, 0.3],\n",
    "            'n_estimators':[100,250,500] ,\n",
    "            'verbosity':[1], \n",
    "            'silent':[0], \n",
    "            'objective':['reg:squarederror'],\n",
    "            'booster':['gbtree'],\n",
    "            'n_jobs':[-1], \n",
    "            'nthread':[-1], \n",
    "            'gamma':[0],  \n",
    "            'reg_alpha':[0], \n",
    "            'reg_lambda':[1],\n",
    "            'importance_type':['gain']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search on the model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,...\n",
       "             param_grid={'booster': ['gbtree'], 'gamma': [0],\n",
       "                         'importance_type': ['gain'],\n",
       "                         'learning_rate': [0.1, 0.3], 'max_depth': [5, 7, 9],\n",
       "                         'n_estimators': [100, 250, 500], 'n_jobs': [-1],\n",
       "                         'nthread': [-1], 'objective': ['reg:squarederror'],\n",
       "                         'reg_alpha': [0], 'reg_lambda': [1], 'silent': [0],\n",
       "                         'verbosity': [1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, feature_names = preprocessing.training_set_preprocessing.preco_features(df)\n",
    "y, _ = preprocessing.training_set_preprocessing.preco_target(df)\n",
    "    \n",
    "    \n",
    "#split train, validation and testing data\n",
    "#cette partie pourra être remplacée par un CV de la librairie sklearn à posteriori\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.999, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, random_state=38)\n",
    "    \n",
    "_,features = preprocessing.training_set_preprocessing.preco_features(df)\n",
    "\n",
    "\n",
    "\n",
    "#Reconstructing data Matrix for Model training\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    \n",
    "    \n",
    "#Model tuning\n",
    "print(\"Performing Grid Search on the model\")\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "reg = GridSearchCV(gbm, param_grid = xgb_grid, cv = 3, verbose = 2, n_jobs = -1)\n",
    "reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_model(df):\n",
    "    #Get data\n",
    "    X, feature_names = preprocessing.training_set_preprocessing.preco_features(df)\n",
    "    y, _ = preprocessing.training_set_preprocessing.preco_target(df)\n",
    "    \n",
    "    \n",
    "    #split train, validation and testing data\n",
    "    #cette partie pourra être remplacée par un CV de la librairie sklearn à posteriori\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.999, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, random_state=38)\n",
    "    \n",
    "    _,features = preprocessing.training_set_preprocessing.preco_features(df)\n",
    "\n",
    "\n",
    "\n",
    "    #Reconstructing data Matrix for Model training\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    \n",
    "    \n",
    "    \n",
    "    htuning = input('Do you want to perform hyperparameter tuning ? (Y/n)')\n",
    "    if htuning == 'Y':\n",
    "        #Model tuning\n",
    "        print(\"Performing Grid Search on the model\")\n",
    "        gbm = xgb.XGBRegressor()\n",
    "\n",
    "        reg = GridSearchCV(gbm, param_grid = xgb_grid, cv = 3, verbose = 2, n_jobs = -1)\n",
    "        reg.fit(X_train,y_train)\n",
    "        \n",
    "        gbm = xgb.train(reg.best_params_, dtrain, num_boost_round = parameters.num_boost_round, evals=watchlist, early_stopping_rounds=parameters.early_stopping_rounds, verbose_eval=50) \n",
    "        \n",
    "    else:\n",
    "        #Model training\n",
    "        print(\"Training a XGBoost model\")\n",
    "        gbm = xgb.train(parameters.xgb_params, dtrain, num_boost_round = parameters.num_boost_round, evals=watchlist, early_stopping_rounds=parameters.early_stopping_rounds, verbose_eval=50)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #Print performance metrics\n",
    "    print(\"\\nPerformance on  training set\")\n",
    "    dtest = xgb.DMatrix(X_train[features])\n",
    "    test_probs = gbm.predict(dtrain)\n",
    "    error_test = metrics.rmspe(y_train.Ventes.values, test_probs)\n",
    "    R_squarred = r2_score(y_train.Ventes.values, test_probs)\n",
    "    adj_2 = metrics.adjusted_r2(feature_names,y_train.Ventes.values, test_probs)\n",
    "    print('RMSPE: {:.6f}'.format(error_test))\n",
    "    print('R Squarred: {:.6f}'.format(R_squarred))\n",
    "    print('R Squarred (adj): {:.6f}'.format(adj_2))\n",
    "    \n",
    "    print(\"\\nPerformance on Validation set\")\n",
    "    yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "    error = metrics.rmspe(y_valid.Ventes.values, yhat)\n",
    "    R_squarred = r2_score(y_valid.Ventes.values, yhat)\n",
    "    adj_2 = metrics.adjusted_r2(feature_names,y_valid.Ventes.values, yhat)\n",
    "    print('RMSPE: {:.6f}'.format(error_test))\n",
    "    print('R Squarred: {:.6f}'.format(R_squarred))\n",
    "    print('R Squarred (adj): {:.6f}'.format(adj_2))\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"\\nPerformance on test set\")\n",
    "    dtest = xgb.DMatrix(X_test[features])\n",
    "    test_probs = gbm.predict(dtest)\n",
    "    error_test = metrics.rmspe(y_test.Ventes.values, test_probs)\n",
    "    R_squarred = r2_score(y_test.Ventes.values, test_probs)\n",
    "    adj_2 = metrics.adjusted_r2(feature_names,y_test.Ventes.values, test_probs)\n",
    "    print('RMSPE: {:.6f}'.format(error_test))\n",
    "    print('R Squarred: {:.6f}'.format(R_squarred))\n",
    "    print('R Squarred (adj): {:.6f}'.format(adj_2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluation metrics\n",
    "    #------------------- Plot feature importances ----------------\n",
    "    xgb.plot_importance(booster = gbm, show_values = False, importance_type = 'gain')\n",
    "    plt.show()\n",
    "    \n",
    "    # ------------------- Perform SHAP Analysis on training data --------------------\n",
    "    #SHAP_Analysis(gbm, X_train, y_train, feature_names)\n",
    "    \n",
    "    ask_save_params = input('Do you want to save these hyperparameters ? (Y/n)')\n",
    "    \n",
    "    if (htuning == 'Y'):\n",
    "        if (ask_save_params == 'Y'):\n",
    "            functions.save_obj(reg.best_params_, 'xgb_params' )\n",
    "        else:\n",
    "        \n",
    "\n",
    "    return gbm, watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
